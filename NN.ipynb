{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1.+np.exp(-x))\n",
    "\n",
    "def sigmoid_back(x):\n",
    "    return sigmoid(x)*(1.-sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "\te = np.exp(x-np.max(x))\n",
    "\treturn e/e.sum(axis=1, keepdims=True)\n",
    "       \n",
    "def onehot(x):\n",
    "    #set 1 on column with highest value\n",
    "    out = []\n",
    "    for i in x:\n",
    "        idx = np.argmax(i)\n",
    "        p = [0,0,0,0]\n",
    "        p[idx] = 1.\n",
    "        out.append(p)\n",
    "    return np.array(out)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    if not (len(y_true) == len(y_pred)):\n",
    "        print('Size of predicted and true labels not equal.')\n",
    "        return 0.0\n",
    "\n",
    "    corr = 0\n",
    "    for i in range(0,len(y_true)):\n",
    "        corr += 1 if (y_true[i] == y_pred[i]).all() else 0\n",
    "\n",
    "    return corr/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "Xin = np.genfromtxt (\"./train_data.csv\", delimiter=\",\")\n",
    "Yin = np.genfromtxt (\"./train_labels.csv\", delimiter=\",\")\n",
    "#take first 22000 samples for training\n",
    "X = Xin[:22000]\n",
    "Y = Yin[:22000]\n",
    "#get last 2754 samples for validation\n",
    "x2 = Xin[-2754:]\n",
    "y2 = Yin[-2754:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\nacc: 0.8407613636363637\n100\nacc: 0.9867386363636363\n200\nacc: 0.9897727272727272\n300\nacc: 0.9914090909090909\n400\nacc: 0.9926136363636363\n500\nacc: 0.9933181818181818\n600\nacc: 0.9939204545454545\n700\nacc: 0.9942840909090909\n800\nacc: 0.9947159090909091\n900\nacc: 0.9950340909090909\n1000\nacc: 0.9953181818181818\n1100\nacc: 0.9955568181818182\n1200\nacc: 0.9957840909090909\n1300\nacc: 0.9960568181818181\n1400\nacc: 0.9962386363636364\n1500\nacc: 0.9964545454545455\n1600\nacc: 0.9966136363636363\n1700\nacc: 0.996840909090909\n1800\nacc: 0.9970795454545455\n1900\nacc: 0.9972272727272727\n"
    }
   ],
   "source": [
    "#learning rate\n",
    "lr = 10e-5\n",
    "\n",
    "#having 32 perceptrons on first layer\n",
    "#create an array of 784*32 weights from a normal random dist \n",
    "#output 4 different classes\n",
    "w1 = np.random.randn(784,32)\n",
    "b1 = np.random.randn(32)\n",
    "w2 = np.random.randn(32,4)\n",
    "b2 = np.random.randn(4)\n",
    "\n",
    "#train 2000 times\n",
    "for epoch in range(2000):\n",
    "#Forward\n",
    "\n",
    "    #mid layer\n",
    "    z1 = X @ w1+b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    #out layer\n",
    "    z2 = a1 @ w2+b2\n",
    "    a2 = softmax(z2)\n",
    "\n",
    "#BackProp\n",
    "\n",
    "    #out layer\n",
    "    dz2 = a2-Y\n",
    "    dw2 = a1.T @ dz2\n",
    "    db2 = dz2.sum(axis=0)\n",
    "\n",
    "    #mid layer\n",
    "    dz1 = sigmoid_back(z1)\n",
    "    da1 = dz2 @ w2.T\n",
    "    dw1 = X.T @ (dz1*da1)\n",
    "    db1 = (da1*dz1).sum(axis=0)\n",
    "\n",
    "    #update weights\n",
    "    w2 = w2-lr*dw2\n",
    "    b2 = b2-lr*db2\n",
    "    w1 = w1-lr*dw1\n",
    "    b1 = b1-lr*db1\n",
    "\n",
    "#Print accuracy every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch)\n",
    "        out = onehot(a2)\n",
    "        incorrect = np.sum(out != Y) / 2.0\n",
    "        acc = 1.-incorrect/(Y.shape[0]*4)\n",
    "        print('acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9893181818181818"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#get final accuracy on training set\n",
    "out = onehot(a2)\n",
    "calc = accuracy(Y, out)\n",
    "calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    z1 = X @ w1 + b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    z2 = a1 @ w2 + b2\n",
    "    a2 = softmax(z2)\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9840232389251997"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#run model with trained weights on validation set\n",
    "out2 = onehot(model(x2))\n",
    "calc = accuracy(y2, out2)\n",
    "calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save weights\n",
    "np.savez('weights.npz', w1=w1, b1=b1, w2=w2, b2=b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(784, 32)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#check weights\n",
    "data = np.load('weights.npz')\n",
    "cw1 = data['w1']\n",
    "cw1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}